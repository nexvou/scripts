# ğŸ“š Kupon.id Scraper Documentation

Dokumentasi lengkap untuk sistem scraper Kupon.id yang powerful dan terstruktur.

## ğŸ“‹ Daftar Isi

- [Architecture Overview](./ARCHITECTURE.md)
- [Core Components](./CORE.md)
- [Scrapers](./SCRAPERS.md)
- [Configuration](./CONFIGURATION.md)
- [Database Integration](./DATABASE.md)
- [Deployment](./DEPLOYMENT.md)
- [Troubleshooting](./TROUBLESHOOTING.md)
- [API Reference](./API.md)

## ğŸš€ Quick Start

### 1. Installation

```bash
npm install
```

### 2. Environment Setup

```bash
cp .env.example .env
# Edit .env with your Supabase credentials
```

### 3. Test System

```bash
npm test
```

### 4. Run Demo

```bash
npm run demo
```

### 5. Start Scraping

```bash
npm run scrape
```

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ScraperManagerâ”‚â”€â”€â”€â”€â”‚  BrowserManager â”‚â”€â”€â”€â”€â”‚  DatabaseManagerâ”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ - Orchestration â”‚    â”‚ - Puppeteer     â”‚    â”‚ - Supabase      â”‚
â”‚ - Scheduling    â”‚    â”‚ - Anti-bot      â”‚    â”‚ - Batch saves   â”‚
â”‚ - Rate limiting â”‚    â”‚ - User agents   â”‚    â”‚ - Caching       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Platform Scrapers                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Shopee    â”‚  Tokopedia  â”‚   Lazada    â”‚  Blibli/Traveloka   â”‚
â”‚             â”‚             â”‚             â”‚       /Grab         â”‚
â”‚ - Flash Saleâ”‚ - Promos    â”‚ - Vouchers  â”‚ - Deals             â”‚
â”‚ - Deals     â”‚ - Cashback  â”‚ - Flash Saleâ”‚ - Travel/Food       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Core Features

### Multi-Platform Support

- **Shopee**: Flash sales, daily discover, brand promotions
- **Tokopedia**: Promo pages, flash sales, cashback offers
- **Lazada**: Flash sales, vouchers, free shipping deals
- **Blibli**: Product deals, voucher scraping
- **Traveloka**: Travel promotions, flight/hotel deals
- **Grab**: Food delivery promos, mart discounts

### Advanced Capabilities

- **Rate Limiting**: Platform-specific intelligent rate limiting
- **Anti-Bot Protection**: User agent rotation, Cloudflare bypass
- **Error Handling**: Retry mechanisms, graceful degradation
- **Scheduling**: Cron-based automated scraping
- **Database Integration**: Batch processing, duplicate handling
- **Logging**: Comprehensive logging with color coding

## ğŸ“Š Data Flow

```
1. ScraperManager â†’ Initialize scrapers for enabled platforms
2. RateLimiter â†’ Check and enforce rate limits
3. BrowserManager â†’ Launch browser with anti-bot measures
4. Platform Scraper â†’ Navigate and extract data
5. Data Processing â†’ Clean and structure extracted data
6. DatabaseManager â†’ Batch save to Supabase
7. Cleanup â†’ Remove expired coupons, update stats
```

## ğŸ› ï¸ Configuration

### Environment Variables

```bash
# Supabase
NEXT_PUBLIC_SUPABASE_URL=your_url
SUPABASE_SERVICE_ROLE_KEY=your_key

# Scraper Settings
SCRAPER_HEADLESS=true
SCRAPER_TIMEOUT=30000
SCRAPER_MAX_ITEMS=50
```

### Platform Configuration

Each platform can be configured in `config/scraper.config.js`:

- URLs to scrape
- CSS selectors for data extraction
- Rate limits and timeouts
- Maximum items per scrape

## ğŸ“ˆ Performance

### Optimization Features

- **Batch Processing**: Save multiple items in single database call
- **Resource Blocking**: Block unnecessary CSS/images for faster loading
- **Intelligent Scrolling**: Load dynamic content efficiently
- **Caching**: Merchant ID caching to reduce database queries
- **Parallel Processing**: Multiple scrapers can run simultaneously

### Monitoring

- Real-time logging with timestamps
- Success/failure tracking per platform
- Performance metrics and statistics
- Error reporting and debugging info

## ğŸ”’ Security

### Anti-Detection Measures

- Random user agent rotation
- Request timing randomization
- Cloudflare bypass capabilities
- CAPTCHA detection and handling

### Data Protection

- Environment variable security
- Service role key usage for database
- Input validation and sanitization
- Error message sanitization

## ğŸš€ Deployment

### Production Setup

1. Set `NODE_ENV=production`
2. Configure Supabase credentials
3. Set up process manager (PM2)
4. Configure monitoring and alerts
5. Set up log rotation

### Scaling Considerations

- Database connection pooling
- Rate limit adjustments
- Memory usage monitoring
- Browser instance management

## ğŸ“ Support

For detailed documentation on specific components, see the individual documentation files in this directory.

For issues and questions:

- Check [Troubleshooting Guide](./TROUBLESHOOTING.md)
- Review [API Reference](./API.md)
- Open GitHub issue for bugs
- Contact development team for support
